<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [antlr-interest] philosophy about translation
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:antlr-interest%40antlr.org?Subject=%5Bantlr-interest%5D%20philosophy%20about%20translation&In-Reply-To=20061011023210.78533.qmail%40web55902.mail.re3.yahoo.com">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="017898.html">
   <LINK REL="Next"  HREF="017906.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[antlr-interest] philosophy about translation</H1>
    <B>Andy Tripp</B> 
    <A HREF="mailto:antlr-interest%40antlr.org?Subject=%5Bantlr-interest%5D%20philosophy%20about%20translation&In-Reply-To=20061011023210.78533.qmail%40web55902.mail.re3.yahoo.com"
       TITLE="[antlr-interest] philosophy about translation">antlr at jazillian.com
       </A><BR>
    <I>Wed Oct 11 11:01:36 PDT 2006</I>
    <P><UL>
        <LI>Previous message: <A HREF="017898.html">[antlr-interest] philosophy about translation
</A></li>
        <LI>Next message: <A HREF="017906.html">[antlr-interest] philosophy about translation
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#17895">[ date ]</a>
              <a href="thread.html#17895">[ thread ]</a>
              <a href="subject.html#17895">[ subject ]</a>
              <a href="author.html#17895">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Loring Craymer wrote:

&gt;<i> Andy--
</I>&gt;<i>
</I>&gt;<i> I deliberately chose your message to respond to because it captured 
</I>&gt;<i> the pragmatic viewpoint--&quot;I had a problem; I solved it; I did not need 
</I>&gt;<i> to use trees&quot;--quite effectively.  That is quite a bit different from 
</I>&gt;<i> the more usual &quot;I tried to use ANTLR's tree facilities and discovered 
</I>&gt;<i> that writing them by hand and using a visitor is easy and clearly is 
</I>&gt;<i> the ONE TRUE SOLUTION to language processing&quot; that appears in the 
</I>&gt;<i> group every so often.  (Although, truth be told, some of your early 
</I>&gt;<i> messages to the group were along that vein, but you have since worked 
</I>&gt;<i> on problems that require multi-pass recognition support and have 
</I>&gt;<i> broadened your horizons.)
</I>&gt;<i>
</I>&gt;<i> &quot;Thinking in trees&quot; does not come automatically.  It is like learning 
</I>&gt;<i> LISP or Forth or one of the functional languages (and, for that 
</I>&gt;<i> matter, object-oriented programming:  there is a lot of badly designed 
</I>&gt;<i> and implemented C++ code out there).  For a time, working with trees 
</I>&gt;<i> is like slogging through molasses, and then you get the &quot;Aha!&quot; 
</I>&gt;<i> experience and things become easy.  It usually is not about designing 
</I>&gt;<i> the perfect tree structure; instead, it is about simplifying the 
</I>&gt;<i> recognition problem and expressing target language constructs in tree 
</I>&gt;<i> form.
</I>
For the record, I had no trouble &quot;getting&quot; LISP when I learned it 25 
years ago. When I started with C++, I don't think I
really &quot;got&quot; OOD, and only started writing real OO code when learning 
Java forced me to. I think the fact that LISP never
became &quot;mainstream&quot; means that it failed to be easy enough to grasp. 
Regardless of how inherently beautiful it is,
if a lot of programmers don't easily &quot;get it&quot;, then it's not that great.

As for tree structures, the AST shapes are pretty arbitrary. Monty's C 
grammar and the two java.g grammars build
similar trees, but there are differences where the only reason for the 
difference is &quot;just because it was designed that way&quot;.
With a one dimensional token stream, we don't have that problem. There's 
one less level obstraction between what's
on the screen and the mental picture in my head. To this day, I'm not 
sure off the top of my head what the AST
is for, say, &quot;public static void main(String[] args) {&quot;. I have trouble 
keeping the C AST, the Java AST, and the mapping
between the two in my head all at once. And this is the most trivial case!
And yet, as a sequence of tokens, there's no mental work at all. What I 
&quot;see&quot; is the same as my mental image.
(And what I &quot;see&quot; is a sequence of tokens, not a sequence of chars).

&gt;<i>
</I>&gt;<i> If I were working on a natural language problem, would I use trees?  
</I>&gt;<i> Sure!  Trees are a very convenient way of capturing semantics into 
</I>&gt;<i> syntactic form.  Would I generate output with a visitor?  For 
</I>&gt;<i> Esperanto or one of the Romance languages, possibly (for these 
</I>&gt;<i> languages, simple syntactic principles apply); for English, that is 
</I>&gt;<i> unlikely--too much &quot;peephole&quot; substitution is necessary to handle 
</I>&gt;<i> special cases.  Instead, I would most likely process the input into a 
</I>&gt;<i> canonical tree with a regular structure (converting input to tree form 
</I>&gt;<i> is about transforming the special cases) and do some form of 
</I>&gt;<i> rule-based substitution for all of the nasty colloquialisms and other 
</I>&gt;<i> special cases.  (In compiler parlance, that is called &quot;peephole 
</I>&gt;<i> optimization&quot;, often an essential for generating good code.)
</I>
And yet, from what my admitedly feeble research found is that NLP 
systems generally don't use a tree.
If they do, it's not at the heart of the system - they are not &quot;tree 
processors&quot;.

&gt;<i>
</I>&gt;<i> As to compilers and compiler technology:  you might be surprised.  
</I>&gt;<i> &quot;Compiler technology&quot; and &quot;language translation technology&quot; are 
</I>&gt;<i> effectively synonyms, and the technical term for the translators you 
</I>&gt;<i> have discussed in this group is &quot;cascading compiler&quot; (or used to be; 
</I>&gt;<i> the term has pretty much disappeared from the literature as compiler 
</I>&gt;<i> technology research has declined in popularity).  Most language 
</I>&gt;<i> translation problems are much simpler than a conventional compiler and 
</I>&gt;<i> are solved using a subset of the algorithms that go into building an 
</I>&gt;<i> optimizing compiler.  
</I>
I always thought a &quot;compiler&quot; was just a translator that happened to 
have an output that's at a lower level than the input - typically
machine code, or byte code. But then, I guess I'm just remembering an 
undergrad compiler class from 20 years ago, and the
dragon book, so I guess I'm no expert.

&gt;<i> Nothing that you have described doing is out of place in a 
</I>&gt;<i> conventional compiler environment.  You might find it interesting to 
</I>&gt;<i> take a look at GNU RTL, used to generate the peephole optimizer for 
</I>&gt;<i> the gcc toolset.
</I>
Huh??? That makes no sense to me. I've described lots of things that are 
completely out of place in
a conventional compiler. A conventional compiler doesn't translate 
library calls, like &quot;printf&quot; to &quot;System.out.println&quot;.
I do stuff like &quot;strcpy(v1, v2) --&gt; v1 = v2&quot;, replacing a C strcpy() 
call with a Java assignment.
No conventional compiler does anything like that, because technically, 
it's wrong!
I rename files, methods, and variables based on user-specified mappings. 
Compilers don't do that.
I could go on.

&gt;<i>
</I>&gt;<i> As to your &quot;unconventional&quot; approach:  I hate to say this, but 
</I>&gt;<i> everything that you have described doing is well documented in the 
</I>&gt;<i> literature.
</I>
Maybe you could point me to something specific. Today I'm adding smarts 
to my GotoRemoverRule that generates code that
is not faster or more compact than what it was producing before, but it 
looks better to the human eye. I doubt that
there's any literature on that.

&gt;<i> I have noticed that &quot;healthy disrespect for conventional approaches&quot; 
</I>&gt;<i> usually translates to &quot;I never check to see if I am reinventing the 
</I>&gt;<i> wheel or not&quot;.  One of the great resources on the web is Citeseer:  
</I>&gt;<i> &lt;<A HREF="http://citeseer.ist.psu.edu/">http://citeseer.ist.psu.edu/</A>&gt;.  It has some of the good early papers 
</I>&gt;<i> on pattern matching and transformation systems.
</I>
I've looked at many, many papers on those. Can you point me to anything 
specific that you
think I'm missing?

I've also noticed that the person who feels like they're &quot;breaking new 
ground&quot; just hasn't done his homework. That's why
I spend so much time typing here - worried that I might be doing that. 
So I'm not just being defensive,
I really am looking for pointers.

Thanks,
Andy

</PRE>



















<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="017898.html">[antlr-interest] philosophy about translation
</A></li>
	<LI>Next message: <A HREF="017906.html">[antlr-interest] philosophy about translation
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#17895">[ date ]</a>
              <a href="thread.html#17895">[ thread ]</a>
              <a href="subject.html#17895">[ subject ]</a>
              <a href="author.html#17895">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://www.antlr.org/mailman/listinfo/antlr-interest">More information about the antlr-interest
mailing list</a><br>
</body></html>
