<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [antlr-interest] Why does Lexer of C++ run time target eat so much memory
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:antlr-interest%40antlr.org?Subject=Re:%20%5Bantlr-interest%5D%20Why%20does%20Lexer%20of%20C%2B%2B%20run%20time%20target%20eat%20so%0A%20much%20memory&In-Reply-To=%3Cop.umadozf7i0hb2k%40jimi%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="032026.html">
   <LINK REL="Next"  HREF="032029.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[antlr-interest] Why does Lexer of C++ run time target eat so much memory</H1>
    <B>Jim Idle</B> 
    <A HREF="mailto:antlr-interest%40antlr.org?Subject=Re:%20%5Bantlr-interest%5D%20Why%20does%20Lexer%20of%20C%2B%2B%20run%20time%20target%20eat%20so%0A%20much%20memory&In-Reply-To=%3Cop.umadozf7i0hb2k%40jimi%3E"
       TITLE="[antlr-interest] Why does Lexer of C++ run time target eat so much memory">jimi at temporal-wave.com
       </A><BR>
    <I>Tue Dec 16 19:08:49 PST 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="032026.html">[antlr-interest] Looking for examples to walk parser tree or	AST with C runtime
</A></li>
        <LI>Next message: <A HREF="032029.html">[antlr-interest] Why does Lexer of C++ run time target eat so	much memory
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#32027">[ date ]</a>
              <a href="thread.html#32027">[ thread ]</a>
              <a href="subject.html#32027">[ subject ]</a>
              <a href="author.html#32027">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>On Tue, 16 Dec 2008 18:28:50 -0800, chain one &lt;<A HREF="http://www.antlr.org/mailman/listinfo/antlr-interest">chainone at gmail.com</A>&gt; wrote:


Thanks Jim,


Your suggestion is very helpful to me.
I have checked my grammar according to your advice and SKIP some useless tokens.
After doing this, the peak memory usage decrease &#194; from 660M to 480M.
However 480M is still a very large number to me.

And I found some strange behaviors of Lexer of ANTLR3 C Runtime.&#194; 

The first two rules of my grammar to be called &#194; when parsing &#194; is:
syntax
	: ISO_HEADER &#194; header_sec data_sec ISO_END&#194; 
	;
header_sec
	: HEADER &#194; file_des file_name file_schema END_SEC&#194; 
	;

I placed breakpoints in both functions.
And the first parameter of function &quot;antlr3CommonTokenStreamSourceNew&quot; &#194; which I think is used to adjust the token buffer size is left to the default value&#194; ANTLR3_SIZE_HINT(1025).
&#194; &#194;  &#194;  &#194;  &#194;  &#194;  &#194; tokens = antlr3CommonTokenStreamSourceNew &#194; (ANTLR3_SIZE_HINT, TOKENSOURCE(lex));

I believe the number of tokens will never exceed 1025 when parsing, but what happened later makes me doubt about this.



When debugging, I found the breakpoint in&#194; syntax rule( top rule) was&#194; triggered&#194; right after parser started to work.
That's OK, because synatx() is called in the main function

But what's strange was , the breakpoint in&#194; header_sec was not be&#194; triggered&#194;  until the memory kept increasing to 478M!!
It is believed that the Lexer kept all the tokens recognized from the large input file in buffer before parser really started to work.
Am I right? If I am, then what does ANTLR3_SIZE_HINT mean? How to adjust the buffer size in C runtime?


2008/12/17 Jim Idle &lt;<A HREF="http://www.antlr.org/mailman/listinfo/antlr-interest">jimi at temporal-wave.com</A>&gt;
On Tue, 16 Dec 2008 15:54:58 -0800, chain one &lt;<A HREF="http://www.antlr.org/mailman/listinfo/antlr-interest">chainone at gmail.com</A>&gt; wrote:

&gt;<i> Still waiting for help
</I>&gt;<i> I just wanna know, if c runtime target is suitable for large input?
</I>
Yes.



&gt;<i>
</I>&gt;<i> On 12/16/08, chain one &lt;<A HREF="http://www.antlr.org/mailman/listinfo/antlr-interest">chainone at gmail.com</A>&gt; wrote:
</I> &gt;&gt; Hi,
&gt;&gt;<i> These days I am writing a parser for a kind of data file using C++. The
</I>&gt;&gt;<i> format of the data file is simple, so the rules are simple.
</I>&gt;&gt;<i> But when I feed a about 20M-size data file to the parser, the parser 
</I> &gt;&gt; eats
&gt;&gt;<i> almost 600M+ memory.
</I>&gt;&gt;<i> I am surprised by this result and I found most memory and time were 
</I>&gt;&gt;<i> consumed
</I>&gt;&gt;<i> by the Lexer.
</I>
There is possibly something not quite right with this then. 

However, a 20M input file is going to generate a lot of tokens and you need all of tokens in order to 
parse the input, hence you are using a lot of memory - especially if a lot of your tokens are just a few characters. If all your tokens were one character then you would need 20M tokens - that would be the worst case and your case will be something less than this.&#194; 

One way to reduce the number of tokens is to use the SKIP(); macro on tokens that you don't need the parser to see, such as ',' or ' ' and so on. Otherwise they are sitting in your token stream for no reason. Only mark them as hidden and keep them in the token stream if you will need to examine them later. Otherwise SKIP them.

I think you are not understanding the interaction. The lexer will run first and will produce a collection of ALL the tokens in the files. ONce it has done this, THEN the parser will run. Hence you have a HUGE number of tokens - many many more than 1024. You don't really need to change the size hint, this is just how many tokens the lexer token factory pre-allocates in one chunk. Increasing it will not change anything much as only the tokens are getting allocated anyway (it is just faster to allocate them in chunks like this).

Looking at what you are parsing tends to make me think you would be better off with a filtering lexer and avoiding the parser altogether. Then you don't need to deal with any tokens, as you can SKIP them all. Or perhaps this language does not lend it self to this kind of lexer/parser interaction if you cannot deal with the huge memory.

Here is another way though and that is to hand craft a lexer that does not pre-allocate tokens like that and override the token stream etc.

Jim
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <A HREF="http://www.antlr.org/pipermail/antlr-interest/attachments/20081216/4a1e6cf3/attachment.html">http://www.antlr.org/pipermail/antlr-interest/attachments/20081216/4a1e6cf3/attachment.html</A> 
</PRE>





<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="032026.html">[antlr-interest] Looking for examples to walk parser tree or	AST with C runtime
</A></li>
	<LI>Next message: <A HREF="032029.html">[antlr-interest] Why does Lexer of C++ run time target eat so	much memory
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#32027">[ date ]</a>
              <a href="thread.html#32027">[ thread ]</a>
              <a href="subject.html#32027">[ subject ]</a>
              <a href="author.html#32027">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://www.antlr.org/mailman/listinfo/antlr-interest">More information about the antlr-interest
mailing list</a><br>
</body></html>
