<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [antlr-interest] Stupid languages, and parsing them
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:antlr-interest%40antlr.org?Subject=Re:%20%5Bantlr-interest%5D%20Stupid%20languages%2C%20and%20parsing%20them&In-Reply-To=%3Cebc876d70904111208k144f18a0h9f60ad65e758ddba%40mail.gmail.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="034000.html">
   <LINK REL="Next"  HREF="034004.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[antlr-interest] Stupid languages, and parsing them</H1>
    <B>Thomas Brandon</B> 
    <A HREF="mailto:antlr-interest%40antlr.org?Subject=Re:%20%5Bantlr-interest%5D%20Stupid%20languages%2C%20and%20parsing%20them&In-Reply-To=%3Cebc876d70904111208k144f18a0h9f60ad65e758ddba%40mail.gmail.com%3E"
       TITLE="[antlr-interest] Stupid languages, and parsing them">tbrandonau at gmail.com
       </A><BR>
    <I>Sat Apr 11 12:08:32 PDT 2009</I>
    <P><UL>
        <LI>Previous message: <A HREF="034000.html">[antlr-interest] Stupid languages, and parsing them
</A></li>
        <LI>Next message: <A HREF="034004.html">[antlr-interest] Stupid languages, and parsing them
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#34001">[ date ]</a>
              <a href="thread.html#34001">[ thread ]</a>
              <a href="subject.html#34001">[ subject ]</a>
              <a href="author.html#34001">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>On Sun, Apr 12, 2009 at 4:45 AM, Sam Barnett-Cormack
&lt;<A HREF="http://www.antlr.org/mailman/listinfo/antlr-interest">s.barnett-cormack at lancaster.ac.uk</A>&gt; wrote:
&gt;<i> Hi all,
</I>&gt;<i>
</I>&gt;<i> In my ongoing project, I need to parse a really crazy structure that
</I>&gt;<i> wants to change the lexing rules dependent on syntactic factors. I hate
</I>&gt;<i> this.
</I>&gt;<i>
</I>&gt;<i> Within the thing I'm talking about, whitespace and comments are handled
</I>&gt;<i> as they are the rest of the time (thankfully). Alphanumeric tokens are
</I>&gt;<i> all one type, and commas are allowed, and '[' and '{' (and closing
</I>&gt;<i> versions of such) have special meaning. Then there's things that are
</I>&gt;<i> &amp;whatever ('&amp;' followed by alphabetic followed by any number of
</I>&gt;<i> alphanumeric). Those are already distinct types. However, once into this
</I>&gt;<i> weird 'zone', most keywords aren't keywords anymore and must be treated
</I>&gt;<i> as alphanumeric tokens.
</I>&gt;<i>
</I>&gt;<i> Now, this state is entered by 'WITH SYNTAX {' (and exited with '}')
</I>&gt;<i>
</I>&gt;<i> The problem is the specification considers the starter to be three
</I>&gt;<i> tokens, and any amount of whitespace and comments is allowed between
</I>&gt;<i> each. I can easily see that I could use gated predicates to switch
</I>&gt;<i> between two lexer &quot;modes&quot;. That's one solution. I can see two broad
</I>&gt;<i> solutions:
</I>&gt;<i>
</I>&gt;<i> 1) Use member variables to track if the most recent non-WS, non-comment
</I>&gt;<i> token was WITH, SYNTAX, and { (a sort of look-behind implemented
</I>&gt;<i> kludgily by putting an action in *every* rule, or by overruling the emit
</I>&gt;<i> stuff to keep track of the last 2 things on the DEFAULT channel), use
</I>&gt;<i> these to switch into crazy-mode where much is different.
</I>&gt;<i>
</I>&gt;<i> 2) Make the parser just accept *everything* within the definition of
</I>&gt;<i> syntax, and deal with in some other way (????) later. It has to be that
</I>&gt;<i> bad, as the &quot;normal&quot; lexer sees '[[' as a token, and the &quot;weird&quot; version
</I>&gt;<i> has to see it as two '[' tokens.
</I>&gt;<i>
</I>&gt;<i> Anyone got any thoughts? Any ideas which would be less pain? Is there
</I>&gt;<i> already some way of tracking recently-emitted token on a specific channel?
</I>You probably want to look at the island grammar example in the
examples pack. Here you switch to an alternate lexer to parse the
block. This is likely easier and more efficient than using predicates.
That has the lexer switching under lexer control so you will have to
deal with the whitespace\comments in your start sequence. You can have
it under parser control
(<A HREF="http://www.antlr.org/wiki/display/ANTLR3/Island+Grammars+Under+Parser+Control">http://www.antlr.org/wiki/display/ANTLR3/Island+Grammars+Under+Parser+Control</A>)
though I think the start sequence is simple enough that you are better
to have it under lexer control. I would think something like:
WITH_SYNTAX: 'WITH' (WS|COMMENT)+ 'SYNTAX' (WS|COMMENT)+ '{' {
enterWithSyntax(); };
would be easier than your lookback idea. If you really want three
seperate tokens then you could override emit to allow multiple tokens.
This is still likely simpler than the alternate.

Tom.

&gt;<i>
</I>&gt;<i> Thanks,
</I>&gt;<i>
</I>&gt;<i> Sam
</I>&gt;<i>
</I>&gt;<i> List: <A HREF="http://www.antlr.org/mailman/listinfo/antlr-interest">http://www.antlr.org/mailman/listinfo/antlr-interest</A>
</I>&gt;<i> Unsubscribe: <A HREF="http://www.antlr.org/mailman/options/antlr-interest/your-email-address">http://www.antlr.org/mailman/options/antlr-interest/your-email-address</A>
</I>&gt;<i>
</I></PRE>



















<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="034000.html">[antlr-interest] Stupid languages, and parsing them
</A></li>
	<LI>Next message: <A HREF="034004.html">[antlr-interest] Stupid languages, and parsing them
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#34001">[ date ]</a>
              <a href="thread.html#34001">[ thread ]</a>
              <a href="subject.html#34001">[ subject ]</a>
              <a href="author.html#34001">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://www.antlr.org/mailman/listinfo/antlr-interest">More information about the antlr-interest
mailing list</a><br>
</body></html>
