<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [antlr-interest] Unicode
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:antlr-interest%40antlr.org?Subject=%5Bantlr-interest%5D%20Unicode&In-Reply-To=">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="015261.html">
   <LINK REL="Next"  HREF="015239.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[antlr-interest] Unicode</H1>
    <B>Don Caton</B> 
    <A HREF="mailto:antlr-interest%40antlr.org?Subject=%5Bantlr-interest%5D%20Unicode&In-Reply-To="
       TITLE="[antlr-interest] Unicode">dcaton at shorelinesoftware.com
       </A><BR>
    <I>Mon Jan 30 05:57:49 PST 2006</I>
    <P><UL>
        <LI>Previous message: <A HREF="015261.html">[antlr-interest] help requested for selective whitespace
</A></li>
        <LI>Next message: <A HREF="015239.html">[antlr-interest] Unicode
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#15238">[ date ]</a>
              <a href="thread.html#15238">[ thread ]</a>
              <a href="subject.html#15238">[ subject ]</a>
              <a href="author.html#15238">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>I know the subject of Unicode comes up now and again, but it seems to me
that at best, the offered solutions are a hack.

It seems that it would be difficult, it not impossible to create a Unicode
parser and lexer from Antlr, given the way it currently generates code (I'm
talking specifically about C++ output here).

The C++ code generator insists on using string, rather than a typedef or
#define that could be set to string or wstring.  And throughout the
generated code as well as the static code, char * is assumed rather than
TCHAR *, single byte literal strings are used, etc. etc.

What's the rationale for this?  Is there something obvious I'm overlooking?
Unicode isn't exactly a new concept.  Why are we limited to the relatively
ancient world of 7 or 8 bit character sets?   

It seems to me that a few typedefs or #defines would make creating true
Unicode lexers and parsers a no-brainer and wouldn't break anything for
those who still need ansi parsers.

BTW, I know you can get a true Unicode parser from the C# code generator,
but I need C++.

Don


</PRE>







<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="015261.html">[antlr-interest] help requested for selective whitespace
</A></li>
	<LI>Next message: <A HREF="015239.html">[antlr-interest] Unicode
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#15238">[ date ]</a>
              <a href="thread.html#15238">[ thread ]</a>
              <a href="subject.html#15238">[ subject ]</a>
              <a href="author.html#15238">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://www.antlr.org/mailman/listinfo/antlr-interest">More information about the antlr-interest
mailing list</a><br>
</body></html>
