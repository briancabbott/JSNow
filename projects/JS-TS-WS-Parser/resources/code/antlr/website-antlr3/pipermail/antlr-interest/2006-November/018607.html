<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [antlr-interest] Parsing Very Large Inputs
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:antlr-interest%40antlr.org?Subject=%5Bantlr-interest%5D%20Parsing%20Very%20Large%20Inputs&In-Reply-To=200611261105.40756.rschulz%40sonic.net">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="018606.html">
   <LINK REL="Next"  HREF="018610.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[antlr-interest] Parsing Very Large Inputs</H1>
    <B>Terence Parr</B> 
    <A HREF="mailto:antlr-interest%40antlr.org?Subject=%5Bantlr-interest%5D%20Parsing%20Very%20Large%20Inputs&In-Reply-To=200611261105.40756.rschulz%40sonic.net"
       TITLE="[antlr-interest] Parsing Very Large Inputs">parrt at cs.usfca.edu
       </A><BR>
    <I>Sun Nov 26 11:48:27 PST 2006</I>
    <P><UL>
        <LI>Previous message: <A HREF="018606.html">[antlr-interest] Parsing Very Large Inputs
</A></li>
        <LI>Next message: <A HREF="018610.html">[antlr-interest] v3 lexer problem
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#18607">[ date ]</a>
              <a href="thread.html#18607">[ thread ]</a>
              <a href="subject.html#18607">[ subject ]</a>
              <a href="author.html#18607">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>hi.  Those streams never throw tokens out.  It creates text based  
upon the tokens in the buffer and operations you perform, but it  
never does a delete...it just skips them during printing.

Implement TokenStream interface and just don't keep the tokens  
around.  I think it's just nextToken() and LT() or something.

Ter
On Nov 26, 2006, at 11:05 AM, Randall R Schulz wrote:

&gt;<i> Hi,
</I>&gt;<i>
</I>&gt;<i> I'm using ANTLR v3 (3.0b5).
</I>&gt;<i>
</I>&gt;<i> If I understand correctly, the Token sequence produced by an ANTLR
</I>&gt;<i> lexical analyzer is retained throughout the parse by  
</I>&gt;<i> CommonTokenStream.
</I>&gt;<i> Ordinarily, this is fine, but when parsing very large inputs, it can
</I>&gt;<i> place an excessive demand on primary storage and become a limiting
</I>&gt;<i> factor for the size of inputs that can be processed without the
</I>&gt;<i> allocation of inordinate amounts of RAM.
</I>&gt;<i>
</I>&gt;<i> It appears that TokenRewriteStream would allow me to discard old Token
</I>&gt;<i> instances once they're no longer needed. In my parser, I do this in
</I>&gt;<i> conjunction with collecting any comment Tokens that may appear between
</I>&gt;<i> top-level constructs in the language.
</I>&gt;<i>
</I>&gt;<i> So I switched to using a TokenRewriteStream and then invoked
</I>&gt;<i> TokenRewriteStream.delete(0, newFirstTokenIndex) after parsing every
</I>&gt;<i> top-level construct (where newFirstTokenIndex is the index of the  
</I>&gt;<i> first
</I>&gt;<i> token in the top-level construct).
</I>&gt;<i>
</I>&gt;<i> However, this does not seem to have the effect on RAM consumption I'd
</I>&gt;<i> hoped. The JavaDoc comment on TokenRewriteStream says the  
</I>&gt;<i> manipulations
</I>&gt;<i> it performs are carried out &quot;lazily,&quot; so I added a call to
</I>&gt;<i> TokenRewriteStream.toString(0, 1) after the delete(...) call. When I
</I>&gt;<i> print this string it shows the text of the newFirstTokenIndex, which
</I>&gt;<i> seems correct.
</I>&gt;<i>
</I>&gt;<i> With this modification, the parse continues normally but it does not
</I>&gt;<i> appear memory use is significantly reduced. I noticed that the token
</I>&gt;<i> indexes associated with the left-hand token of successive top-level
</I>&gt;<i> constructs increase as if no Token deletion was performed, though I'm
</I>&gt;<i> guessing that's as intended.
</I>&gt;<i>
</I>&gt;<i> Apparently, the Token structures remain and only the text to which  
</I>&gt;<i> they
</I>&gt;<i> refer is discarded. It also seems, based on the comments for
</I>&gt;<i> TokenRewriteStream that a lot of bookkeeping is put in place to record
</I>&gt;<i> the manipulations.
</I>&gt;<i>
</I>&gt;<i> Is there a simpler way to simply and completely discard old Tokens?
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> Randall Schulz
</I>
</PRE>
















<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="018606.html">[antlr-interest] Parsing Very Large Inputs
</A></li>
	<LI>Next message: <A HREF="018610.html">[antlr-interest] v3 lexer problem
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#18607">[ date ]</a>
              <a href="thread.html#18607">[ thread ]</a>
              <a href="subject.html#18607">[ subject ]</a>
              <a href="author.html#18607">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://www.antlr.org/mailman/listinfo/antlr-interest">More information about the antlr-interest
mailing list</a><br>
</body></html>
