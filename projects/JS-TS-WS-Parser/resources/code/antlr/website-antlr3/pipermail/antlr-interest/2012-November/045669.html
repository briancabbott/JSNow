<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [antlr-interest] Huge tables in C lexers
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:antlr-interest%40antlr.org?Subject=Re:%20%5Bantlr-interest%5D%20Huge%20tables%20in%20C%20lexers&In-Reply-To=%3C07B9B91B-0BB9-4BF8-8AD8-0CAEC3E86887%40lischke-online.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="045665.html">
   <LINK REL="Next"  HREF="045646.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[antlr-interest] Huge tables in C lexers</H1>
    <B>Mike Lischke</B> 
    <A HREF="mailto:antlr-interest%40antlr.org?Subject=Re:%20%5Bantlr-interest%5D%20Huge%20tables%20in%20C%20lexers&In-Reply-To=%3C07B9B91B-0BB9-4BF8-8AD8-0CAEC3E86887%40lischke-online.de%3E"
       TITLE="[antlr-interest] Huge tables in C lexers">mike at lischke-online.de
       </A><BR>
    <I>Sun Nov 11 02:17:03 PST 2012</I>
    <P><UL>
        <LI>Previous message: <A HREF="045665.html">[antlr-interest] Huge tables in C lexers
</A></li>
        <LI>Next message: <A HREF="045646.html">[antlr-interest] AUTO: Noel Dcosta is out of the office (returning	11/15/2012)
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#45669">[ date ]</a>
              <a href="thread.html#45669">[ thread ]</a>
              <a href="subject.html#45669">[ subject ]</a>
              <a href="author.html#45669">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Hey Jim,

&gt;<i> You mis-understand Mike. The situation is pretty much the exact opposite
</I>&gt;<i> of what you suggest. Java has to do what it does because there is no way
</I>&gt;<i> to declare character arrays with pre-initialized data. C/C++ is streets
</I>&gt;<i> ahead in this regard.
</I>
I guess you mis-understood me. It's not that I judge one handling over the other wrt execution. My concern is rather the big source file, which takes a lot of time to load into a debugger. This is even worse with an IDE like XCode, which has a hard time to cope with so large files. Also other tools like SCMs get to their limit when you try to view a diff of such huge files, do some pre-commit processing and what not. Runtime behavior is not the only aspect ...

&gt;<i> While these days, the tables are not a big deal, you should still limit
</I>&gt;<i> them by making your lexer leaner. You are probably telling the lexer to
</I>&gt;<i> pick out certain classes of characters (from a spec?).
</I>
Only this:

// As defined in <A HREF="http://dev.mysql.com/doc/refman/5.6/en/identifiers.html.">http://dev.mysql.com/doc/refman/5.6/en/identifiers.html.</A>
fragment LETTER_WHEN_UNQUOTED:
	'0'..'9'
	| 'A'..'Z' // Only upper case, as we use a case insensitive parser (insensitive only for ASCII).
	| '$'
	| '_'
	| '\u0080'..'\uffff'
;

When I comment out the last alt I get a much smaller lexer source file.

&gt;<i> It is better to
</I>&gt;<i> relax lexer rules and get them to recognize the roughly correct pattern,
</I>&gt;<i> then check the character set and issue a semantic error. If you get a
</I>&gt;<i> lexer error, all you can do is say &quot;invalid character&quot; and it pretty much
</I>&gt;<i> ends the sequence. Move your errors as far in to the tool chain as you
</I>&gt;<i> can, because you will give your users much better context in the errors.
</I>

You have said this already many times and I try to follow your advice as much as I can (because it makes a lot of sense) but in such a case it's totally ok to immediately stop processing and say: &quot;nonsense char found, fix it&quot;. Why doing a whole chain of processing if it is just a wrong char that the user entered?

To test the outcome I changed the rule above to just:

fragment LETTER_WHEN_UNQUOTED:
	.
;

which not only brought me a warning about 3 other rules which cannot be matched anymore (even though this rule is essentially the last one in my grammar, only followed by 2 virtual tokens), but it also increased the lexer source size to 55MB (from 38MB)! So, relaxing the lexer seems not to be a solution for this problem. The only way to get the size down is to exclude certain input.

Mike
-- 
www.soft-gems.net


</PRE>








<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="045665.html">[antlr-interest] Huge tables in C lexers
</A></li>
	<LI>Next message: <A HREF="045646.html">[antlr-interest] AUTO: Noel Dcosta is out of the office (returning	11/15/2012)
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#45669">[ date ]</a>
              <a href="thread.html#45669">[ thread ]</a>
              <a href="subject.html#45669">[ subject ]</a>
              <a href="author.html#45669">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://www.antlr.org/mailman/listinfo/antlr-interest">More information about the antlr-interest
mailing list</a><br>
</body></html>
