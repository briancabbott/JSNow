<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [antlr-interest] Streaming Support
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:antlr-interest%40antlr.org?Subject=Re:%20%5Bantlr-interest%5D%20Streaming%20Support&In-Reply-To=%3CB9006942-799C-4CD0-8AC7-DE447BAAC902%40gmail.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="038662.html">
   <LINK REL="Next"  HREF="038660.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[antlr-interest] Streaming Support</H1>
    <B>Horst Dehmer</B> 
    <A HREF="mailto:antlr-interest%40antlr.org?Subject=Re:%20%5Bantlr-interest%5D%20Streaming%20Support&In-Reply-To=%3CB9006942-799C-4CD0-8AC7-DE447BAAC902%40gmail.com%3E"
       TITLE="[antlr-interest] Streaming Support">horst.dehmer at gmail.com
       </A><BR>
    <I>Mon May 17 07:01:27 PDT 2010</I>
    <P><UL>
        <LI>Previous message: <A HREF="038662.html">[antlr-interest] Error handling using parallel instances of a	C-target parser
</A></li>
        <LI>Next message: <A HREF="038660.html">[antlr-interest] ANTLR Two Simple Questions :-)
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#38659">[ date ]</a>
              <a href="thread.html#38659">[ thread ]</a>
              <a href="subject.html#38659">[ subject ]</a>
              <a href="author.html#38659">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Hi there,

I'd like to parse 'large' streams (200 MBytes and more) with only  
small chunks of data (tokens/characters) in memory at a time.
The goal is that the parser/lexer should block until more chars are  
available from the underlying input stream. I have a few simple  
'callbacks' embedded in the grammar which call into the business logic  
to process recognized data. But with the standard setup, the callbacks  
are just called after the complete input stream was read.

// uncompressed replication transaction.
transaction
   : { if(callback != null) callback.startTransaction(); }
     x01 (update_type)+
     { if(callback != null) callback.endTransaction(); }
   ;

update_type
   : entityId = entity_id '{' (values = basic_update)+ '}'
     { if(callback != null) callback.updateType(entityId, values); }
   ;

basic_update returns [List&lt;String&gt; values]
@init {
   values = new ArrayList&lt;String&gt;();
}
   : '{' s = value { values.add(s); } ('|' (s = value  
{ values.add(s); } )? )* '}'
   ;

There are a few reasons why I'd like to do it this way:

1. the data is received in rather small chunks (&lt; 4k or so) from NIO  
sockets
2. I don't want to buffer the data on the file system (file I/O)
3. have as small a memory footprint as possible
4. it is possible that many streams are processed/parsed at one time

I'm using ANTLR 3.1.3 (Java/Scala).

 From what I see CommonTokenStream.fillBuffer() is pretty greedy and  
loads all tokens at once. Right now I'm using ANTLRInputStream as the  
CharStream.

Is there a (simple) way to accomplish this? What would be the right  
approach: a custom Token Stream or rather another Char Stream? BTW:  
Lookahead of 1 is fine for me.

Thanks for your help.

Cheers,
	Horst


</PRE>



<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="038662.html">[antlr-interest] Error handling using parallel instances of a	C-target parser
</A></li>
	<LI>Next message: <A HREF="038660.html">[antlr-interest] ANTLR Two Simple Questions :-)
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#38659">[ date ]</a>
              <a href="thread.html#38659">[ thread ]</a>
              <a href="subject.html#38659">[ subject ]</a>
              <a href="author.html#38659">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://www.antlr.org/mailman/listinfo/antlr-interest">More information about the antlr-interest
mailing list</a><br>
</body></html>
