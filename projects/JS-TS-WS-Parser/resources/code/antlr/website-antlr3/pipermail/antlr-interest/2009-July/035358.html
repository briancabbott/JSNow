<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [antlr-interest] Help with discarding lexer tokens....
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:antlr-interest%40antlr.org?Subject=Re:%20%5Bantlr-interest%5D%20Help%20with%20discarding%20lexer%20tokens....&In-Reply-To=%3C8d80b1570907271010w4fbf8308y787eb0a40e6e9dfb%40mail.gmail.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="035336.html">
   <LINK REL="Next"  HREF="035312.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[antlr-interest] Help with discarding lexer tokens....</H1>
    <B>Fredrik Ohrstrom</B> 
    <A HREF="mailto:antlr-interest%40antlr.org?Subject=Re:%20%5Bantlr-interest%5D%20Help%20with%20discarding%20lexer%20tokens....&In-Reply-To=%3C8d80b1570907271010w4fbf8308y787eb0a40e6e9dfb%40mail.gmail.com%3E"
       TITLE="[antlr-interest] Help with discarding lexer tokens....">oehrstroem at gmail.com
       </A><BR>
    <I>Mon Jul 27 10:10:50 PDT 2009</I>
    <P><UL>
        <LI>Previous message: <A HREF="035336.html">[antlr-interest] Help with discarding lexer tokens....
</A></li>
        <LI>Next message: <A HREF="035312.html">[antlr-interest] wildcard string in grammar
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#35358">[ date ]</a>
              <a href="thread.html#35358">[ thread ]</a>
              <a href="subject.html#35358">[ subject ]</a>
              <a href="author.html#35358">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>I tried explicit tokens as well, but it still uses too little lookahead.
I did finally solve it in a reasonable way, i.e. the grammar
stays unchanged, and I can add any number of weird discard rules.
:<i>-)
</I>
grammar Test;
cmd :  (CMD suffix? )* ;
suffix : '[' CMD ']'  ;
CMD : 'a'..'z'+ ;
DISCARD : { (input.LA(1)=='[' &amp;&amp;
                      input.LA(2)=='r' &amp;&amp;
                      input.LA(3)=='e' &amp;&amp;
                      input.LA(4)=='m &amp;&amp;
                      input.LA(5)=='o' &amp;&amp;
                      input.LA(6)=='v' &amp;&amp;
                      input.LA(7)=='e &amp;&amp;
                      input.LA(8)==']') } ?=&gt; '[remove]' { $channel=HIDDEN; } ;
WS : (' '|'\t'|'\r'|'\n')+ { $channel=HIDDEN; } ;

Thanks!

2009/7/23 David-Sarah Hopwood &lt;<A HREF="http://www.antlr.org/mailman/listinfo/antlr-interest">david-sarah at jacaranda.org</A>&gt;:
&gt;<i> David-Sarah Hopwood wrote:
</I>&gt;&gt;<i> Fredrik Ohrstrom wrote:
</I>&gt;&gt;&gt;<i> I would like to ignore certain tokens found at the lexer level.
</I>&gt;&gt;&gt;<i> For example: my example source code is sprinkled with tokens
</I>&gt;&gt;&gt;<i> like [remove] and I want to prevent these to be seen by the parser.
</I>&gt;&gt;<i> [...]
</I>&gt;&gt;&gt;<i> I did finally stumble upon a solution, but it is ugly.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> grammar Test;
</I>&gt;&gt;&gt;<i> cmd &#160;: &#160;(CMD suffix? )* ;
</I>&gt;&gt;&gt;<i> suffix : LB CMD RB ;
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> &#160; suffix : LB c=CMD RB
</I>&gt;&gt;<i> &#160; &#160; { if ($c != null &amp;&amp; $c.text.equals(&quot;remove&quot;)) $channel = HIDDEN; } ;
</I>&gt;<i>
</I>&gt;<i> Sorry, setting $channel only makes sense in a lexer rule, so this won't
</I>&gt;<i> work as written.
</I>&gt;<i>
</I>&gt;<i> Rather than using the explicit test above, I think it is probably more
</I>&gt;<i> elegant to declare &quot;[remove]&quot; in the tokens block (which gives it precedence
</I>&gt;<i> over other rules that it would otherwise be ambiguous with), like this:
</I>&gt;<i>
</I>&gt;<i> &#160;grammar Test;
</I>&gt;<i>
</I>&gt;<i> &#160;tokens {
</I>&gt;<i> &#160; &#160;REMOVE: '[remove]';
</I>&gt;<i> &#160;}
</I>&gt;<i>
</I>&gt;<i> &#160;// should probably rename this rule for clarity
</I>&gt;<i> &#160;cmd : (Cmd Suffix?)* ;
</I>&gt;<i>
</I>&gt;<i> &#160;Remove : REMOVE { $channel = HIDDEN; } ;
</I>&gt;<i>
</I>&gt;<i> &#160;Suffix : '[' CMD ']' ;
</I>&gt;<i>
</I>&gt;<i> &#160;Cmd : CMD ;
</I>&gt;<i>
</I>&gt;<i> &#160;fragment CMD : ('a'..'z')+ ;
</I>&gt;<i>
</I>&gt;<i> &#160;WS : (' '|'\t'|'\r'|'\n')+ { $channel=HIDDEN; } ;
</I>&gt;<i>
</I>&gt;<i> This allows whitespace between Cmd and Suffix, or between multiple
</I>&gt;<i> Suffixes. It wasn't clear from your original post whether you want
</I>&gt;<i> to allow whitespace there or not.
</I>&gt;<i>
</I>&gt;&gt;<i> Thanks! But as I wrote in the other email, suffix is
</I>&gt;&gt;<i> unfortunately really complicated and occurs in
</I>&gt;&gt;<i> several different places in the parser.
</I>&gt;<i>
</I>&gt;<i> Given the correction above, is there still a problem?
</I>&gt;<i> Suffix could be made arbitrarily complicated and used in any number
</I>&gt;<i> of places.
</I>&gt;<i>
</I>&gt;<i> --
</I>&gt;<i> David-Sarah Hopwood &#160;&#9893; &#160;<A HREF="http://davidsarah.livejournal.com">http://davidsarah.livejournal.com</A>
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> List: <A HREF="http://www.antlr.org/mailman/listinfo/antlr-interest">http://www.antlr.org/mailman/listinfo/antlr-interest</A>
</I>&gt;<i> Unsubscribe: <A HREF="http://www.antlr.org/mailman/options/antlr-interest/your-email-address">http://www.antlr.org/mailman/options/antlr-interest/your-email-address</A>
</I>&gt;<i>
</I></PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="035336.html">[antlr-interest] Help with discarding lexer tokens....
</A></li>
	<LI>Next message: <A HREF="035312.html">[antlr-interest] wildcard string in grammar
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#35358">[ date ]</a>
              <a href="thread.html#35358">[ thread ]</a>
              <a href="subject.html#35358">[ subject ]</a>
              <a href="author.html#35358">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://www.antlr.org/mailman/listinfo/antlr-interest">More information about the antlr-interest
mailing list</a><br>
</body></html>
