<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [antlr-interest] Lexer question
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:antlr-interest%40antlr.org?Subject=%5Bantlr-interest%5D%20Lexer%20question&In-Reply-To=">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="014772.html">
   <LINK REL="Next"  HREF="014781.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[antlr-interest] Lexer question</H1>
    <B>Ari Steinberg</B> 
    <A HREF="mailto:antlr-interest%40antlr.org?Subject=%5Bantlr-interest%5D%20Lexer%20question&In-Reply-To="
       TITLE="[antlr-interest] Lexer question">Ari.Steinberg at EMBARCADERO.COM
       </A><BR>
    <I>Mon Dec 12 12:29:37 PST 2005</I>
    <P><UL>
        <LI>Previous message: <A HREF="014772.html">[antlr-interest] Delimited identifiers and suffix functions
</A></li>
        <LI>Next message: <A HREF="014781.html">[antlr-interest] Re: Lexer question
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#14773">[ date ]</a>
              <a href="thread.html#14773">[ thread ]</a>
              <a href="subject.html#14773">[ subject ]</a>
              <a href="author.html#14773">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Hi Guys,

Hopefully someone can help me out.  I would like my lexer to create a
special INVALID_CHARACTER token for any invalid characters it finds and
send them along to the parser so that it can be handled in the parser.

I have my char vocabulary set to '\0'..'\377' and have the filter option
set to a INVALID_CHARACTER.  This way all invalid characters ( such as
Unicode characters ) are matched by the filter rule.

Doing this I can report the character as an error but I really do need
that character to still be a part of the token stream ( rather then
ignored ).  So far the only way I've thought of to be able to accomplish
this is to make all my rules protected and have one giant rule that
matches all my subrules, this would be a major pain.  It's either that
or hack into the lexer generator and make the filter rule create and
return a token.

Any one have any better ideas?

Thanks,
Ari

Ari Steinberg
Engineer Extraordinaire @
Embarcadero Technologies
416-593-1585 x231
ari.steinberg at embarcadero.com
</PRE>








<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="014772.html">[antlr-interest] Delimited identifiers and suffix functions
</A></li>
	<LI>Next message: <A HREF="014781.html">[antlr-interest] Re: Lexer question
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#14773">[ date ]</a>
              <a href="thread.html#14773">[ thread ]</a>
              <a href="subject.html#14773">[ subject ]</a>
              <a href="author.html#14773">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://www.antlr.org/mailman/listinfo/antlr-interest">More information about the antlr-interest
mailing list</a><br>
</body></html>
