<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [antlr-interest] C target memory usage
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:antlr-interest%40antlr.org?Subject=Re:%20%5Bantlr-interest%5D%20C%20target%20memory%20usage&In-Reply-To=%3CCACCG97HEYGcEM8_adGzZNQw782g32wovzxd1yqLuM%2Bma5uD3bQ%40mail.gmail.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="043529.html">
   <LINK REL="Next"  HREF="043537.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[antlr-interest] C target memory usage</H1>
    <B>Richard Gildea</B> 
    <A HREF="mailto:antlr-interest%40antlr.org?Subject=Re:%20%5Bantlr-interest%5D%20C%20target%20memory%20usage&In-Reply-To=%3CCACCG97HEYGcEM8_adGzZNQw782g32wovzxd1yqLuM%2Bma5uD3bQ%40mail.gmail.com%3E"
       TITLE="[antlr-interest] C target memory usage">rgildea at gmail.com
       </A><BR>
    <I>Thu Dec 22 20:00:02 PST 2011</I>
    <P><UL>
        <LI>Previous message: <A HREF="043529.html">[antlr-interest] De-emphasizing tree grammars?
</A></li>
        <LI>Next message: <A HREF="043537.html">[antlr-interest] C target memory usage
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#43530">[ date ]</a>
              <a href="thread.html#43530">[ thread ]</a>
              <a href="subject.html#43530">[ subject ]</a>
              <a href="author.html#43530">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Hi,

We have been successfully using antlr in the form of the C target for some
time, however we have recently noticed that the memory consumption can be
quite large - up to 150 times the size of the input file. Is this factor of
~150 to be expected, or does it indicate that we may be doing something
wrong? For the vast majority of possible inputs this does not cause a
problem, however some input files can be as large as 0.5 Gb, giving a peak
memory usage of 75 Gb - not exactly feasible on most machines!

Does anyone have any examples of using a custom lexer that provides a token
buffer rather than storing all tokens in memory?

Cheers,

Richard
</PRE>







<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="043529.html">[antlr-interest] De-emphasizing tree grammars?
</A></li>
	<LI>Next message: <A HREF="043537.html">[antlr-interest] C target memory usage
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#43530">[ date ]</a>
              <a href="thread.html#43530">[ thread ]</a>
              <a href="subject.html#43530">[ subject ]</a>
              <a href="author.html#43530">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://www.antlr.org/mailman/listinfo/antlr-interest">More information about the antlr-interest
mailing list</a><br>
</body></html>
