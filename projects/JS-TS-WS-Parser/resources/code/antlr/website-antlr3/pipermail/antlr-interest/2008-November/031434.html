<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [antlr-interest] Parsing huge files a chunk at a time
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:antlr-interest%40antlr.org?Subject=Re:%20%5Bantlr-interest%5D%20Parsing%20huge%20files%20a%20chunk%20at%20a%20time&In-Reply-To=%3C4913A359.3050007%40gmail.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="031429.html">
   <LINK REL="Next"  HREF="031454.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[antlr-interest] Parsing huge files a chunk at a time</H1>
    <B>John Woods</B> 
    <A HREF="mailto:antlr-interest%40antlr.org?Subject=Re:%20%5Bantlr-interest%5D%20Parsing%20huge%20files%20a%20chunk%20at%20a%20time&In-Reply-To=%3C4913A359.3050007%40gmail.com%3E"
       TITLE="[antlr-interest] Parsing huge files a chunk at a time">jqwoods at gmail.com
       </A><BR>
    <I>Thu Nov  6 18:09:29 PST 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="031429.html">[antlr-interest] change ANTLRs (generated) grammarFileName?
</A></li>
        <LI>Next message: <A HREF="031454.html">[antlr-interest] Parsing huge files a chunk at a time
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#31434">[ date ]</a>
              <a href="thread.html#31434">[ thread ]</a>
              <a href="subject.html#31434">[ subject ]</a>
              <a href="author.html#31434">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Hello,

I'd like to parse files which are much larger than my target memory 
footprint. The files are composed of many small independently parsable 
chunks. I only need to parse one of these chunks at a time, dispose of 
the parsed result, then parse the next chunk.

The first hurdle I find is that ANTLRReaderStream reads the entire file 
into a memory buffer upon construction. So, I thought I'd implement 
MyOwnReaderStream class which implements the CharStream interface such 
that only as many chars as look-ahead requests are read into memory 
(using a relatively small look-ahead buffer backed by a RandomAccessFile 
to support long distance marks, etc).

However, it seems that even if I did that, the next hurdle would be 
CommonTokenStream.fillBuffer() which again tries to tokenize everything 
into memory even though it's not needed yet.

Is there a way to only consume memory on the order of the size of the 
rule I'm attempting to parse, and not on the order of the size of the file?

Thanks for any tips!
</PRE>





<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="031429.html">[antlr-interest] change ANTLRs (generated) grammarFileName?
</A></li>
	<LI>Next message: <A HREF="031454.html">[antlr-interest] Parsing huge files a chunk at a time
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#31434">[ date ]</a>
              <a href="thread.html#31434">[ thread ]</a>
              <a href="subject.html#31434">[ subject ]</a>
              <a href="author.html#31434">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://www.antlr.org/mailman/listinfo/antlr-interest">More information about the antlr-interest
mailing list</a><br>
</body></html>
