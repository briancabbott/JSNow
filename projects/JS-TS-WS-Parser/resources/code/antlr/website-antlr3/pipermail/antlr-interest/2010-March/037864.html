<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [antlr-interest] Out of memory - how to avoid retaining all tokens??
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:antlr-interest%40antlr.org?Subject=Re:%20%5Bantlr-interest%5D%20Out%20of%20memory%20-%20how%20to%20avoid%20retaining%20all%20tokens%3F%3F&In-Reply-To=%3C%21%26%21AAAAAAAAAAAYAAAAAAAAAJ6HnVdlvLVNnvOxG5JxQq7CgAAAEAAAABELblLEUIJCgbuL3EQTkpgBAAAAAA%3D%3D%40ision.nl%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="037859.html">
   <LINK REL="Next"  HREF="037868.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[antlr-interest] Out of memory - how to avoid retaining all tokens??</H1>
    <B>John Pool</B> 
    <A HREF="mailto:antlr-interest%40antlr.org?Subject=Re:%20%5Bantlr-interest%5D%20Out%20of%20memory%20-%20how%20to%20avoid%20retaining%20all%20tokens%3F%3F&In-Reply-To=%3C%21%26%21AAAAAAAAAAAYAAAAAAAAAJ6HnVdlvLVNnvOxG5JxQq7CgAAAEAAAABELblLEUIJCgbuL3EQTkpgBAAAAAA%3D%3D%40ision.nl%3E"
       TITLE="[antlr-interest] Out of memory - how to avoid retaining all tokens??">j.pool at ision.nl
       </A><BR>
    <I>Thu Mar  4 23:32:35 PST 2010</I>
    <P><UL>
        <LI>Previous message: <A HREF="037859.html">[antlr-interest] Macro redefinition warnings from libantlr3c	headers
</A></li>
        <LI>Next message: <A HREF="037868.html">[antlr-interest] Fwd:  passing arguments to the templates
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#37864">[ date ]</a>
              <a href="thread.html#37864">[ thread ]</a>
              <a href="subject.html#37864">[ subject ]</a>
              <a href="author.html#37864">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>I have an ANTLR application with which I process a large (100Mb) file by
means of a filter grammar (@options{filter=true;}), in search of a simple
pattern. No backtracking is necessary. Each time the pattern is found, a
call is made to a (C#) method that does some bookkeeping. 

The file is scanned with the following loop: 

while (lexer.NextToken () != Token.EOF_TOKEN) { } 

When the pattern is encountered, the C# method is called. From 'the book' at
section 5.8 (filter option) I understood that 'the lexer yields an
incomplete stream of tokens'. This, however, does not prevent an out of
memory exception to occur after a while. 

How can I prevent this from happening? No backtracking whatsoever needs to
occur, so I do not need a token history to be retained during the execution
of the above loop. I have tried inserting {Skip();} statements, but this
does not seem to help.

I noticed that the exception does not occur (and scanning the file goes
considerably faster) when in lexer.NextToken() I comment out 

int m = input.Mark(); 

and 

input.Rewind(m); 

 

but I am not sure what undesired effect this may have.

 

Regards, John Pool

 

</PRE>








<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="037859.html">[antlr-interest] Macro redefinition warnings from libantlr3c	headers
</A></li>
	<LI>Next message: <A HREF="037868.html">[antlr-interest] Fwd:  passing arguments to the templates
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#37864">[ date ]</a>
              <a href="thread.html#37864">[ thread ]</a>
              <a href="subject.html#37864">[ subject ]</a>
              <a href="author.html#37864">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://www.antlr.org/mailman/listinfo/antlr-interest">More information about the antlr-interest
mailing list</a><br>
</body></html>
