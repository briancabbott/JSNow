<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [antlr-interest] Match any unicode character
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:antlr-interest%40antlr.org?Subject=Re:%20%5Bantlr-interest%5D%20Match%20any%20unicode%20character&In-Reply-To=%3CB1D180FB-4F4D-4D33-9074-957061812792%40gmail.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="025020.html">
   
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[antlr-interest] Match any unicode character</H1>
    <B>Basil Shkara</B> 
    <A HREF="mailto:antlr-interest%40antlr.org?Subject=Re:%20%5Bantlr-interest%5D%20Match%20any%20unicode%20character&In-Reply-To=%3CB1D180FB-4F4D-4D33-9074-957061812792%40gmail.com%3E"
       TITLE="[antlr-interest] Match any unicode character">bshkara at gmail.com
       </A><BR>
    <I>Fri Nov 30 18:14:12 PST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="025020.html">[antlr-interest] Using semantic predicates with antlr 3 and	pythonruntime
</A></li>
        
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#25021">[ date ]</a>
              <a href="thread.html#25021">[ thread ]</a>
              <a href="subject.html#25021">[ subject ]</a>
              <a href="author.html#25021">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Thanks Harald for your suggestions.  They were very helpful.

I'll document my issues and the solutions I came across in case  
someone else is stuck with the same problem.

I have now rewritten my grammar and it operates somewhat as expected  
now.  The issue before was that I failed to take into account  
accurately, the way the lexer consumed my specified tokens.  As well I  
was specifying huge token ranges like ~(WS | NEWLINE)+ in the midst of  
other token declarations which caused the tokens below to be  
unreachable.

The current implementation of my grammar no longer relies upon  
negating alternates like the token above.  Instead I define all my  
tokens and then have a final catch all token:
OTHER	:	.;
which captures everything else not previously consumed above.   
Terrence's book provided the insight for this behaviour.

Then when specifying parser rules it becomes simple to specify a valid  
range of characters which are acceptable such as:
text	:	OTHER | DOUBLEQUOTE | SINGLEQUOTE;

This then allows me to use this rule in another rule defining the  
specific text I want recognised to add to my AST or perform an action:
recognised	:	COLON text+ COLON;
Because COLON is defined above OTHER, the COLON tokens are already  
consumed and so will not be parsed in rule: text.

So by approaching the grammar design this way, the parser is able to  
accept any valid unicode characters possible within the constraints of  
the rules.

Hope this helps someone!
Baz.
</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="025020.html">[antlr-interest] Using semantic predicates with antlr 3 and	pythonruntime
</A></li>
	
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#25021">[ date ]</a>
              <a href="thread.html#25021">[ thread ]</a>
              <a href="subject.html#25021">[ subject ]</a>
              <a href="author.html#25021">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://www.antlr.org/mailman/listinfo/antlr-interest">More information about the antlr-interest
mailing list</a><br>
</body></html>
